{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0400fe14",
   "metadata": {},
   "source": [
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e5f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07911cfa",
   "metadata": {},
   "source": [
    "## Feature engineering ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbae150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(current_meet, previous_meet):\n",
    "    features = current_meet.copy()\n",
    "\n",
    "    features['prev_squat'] = previous_meet['Best3SquatKg'].iloc[-1]\n",
    "    features['prev_bench'] = previous_meet['Best3BenchKg'].iloc[-1]\n",
    "    features['prev_deadlift'] = previous_meet['Best3DeadliftKg'].iloc[-1]\n",
    "\n",
    "    features['avg_squat'] = previous_meet['Best3SquatKg'].mean()\n",
    "    features['avg_bench'] = previous_meet['Best3BenchKg'].mean()\n",
    "    features['avg_deadlift'] = previous_meet['Best3DeadliftKg'].mean()\n",
    "    \n",
    "    features['days_since_last_meet'] = (\n",
    "        pd.to_datetime(current_meet['Date']) - pd.to_datetime(previous_meet['Date'].iloc[-1])\n",
    "    ).days\n",
    "    features['total_meets'] = len(previous_meet)\n",
    "    \n",
    "    # total kg lifted to bodyweight ratio on previous meet\n",
    "    features['total_bodyweight_ratio'] = previous_meet['TotalKg'].iloc[-1] / previous_meet['BodyweightKg'].iloc[-1]\n",
    "    \n",
    "    if len(previous_meet) >= 2:\n",
    "        features['percent_gain_since_last'] = (\n",
    "            (previous_meet['TotalKg'].iloc[-1] - previous_meet['TotalKg'].iloc[-2]) / \n",
    "            previous_meet['TotalKg'].iloc[-2]\n",
    "        )\n",
    "        features['avg_improvement_rate'] = (\n",
    "            (previous_meet['TotalKg'].iloc[-1] - previous_meet['TotalKg'].iloc[0]) / \n",
    "            (len(previous_meet) - 1) / previous_meet['TotalKg'].iloc[0]\n",
    "        )\n",
    "        features['bodyweight_change'] = previous_meet['BodyweightKg'].iloc[-1] - previous_meet['BodyweightKg'].iloc[-2]\n",
    "    else:\n",
    "        features['percent_gain_since_last'] = 0\n",
    "        features['avg_improvement_rate'] = 0\n",
    "        features['bodyweight_change'] = 0\n",
    "    \n",
    "    features['total_std'] = previous_meet['TotalKg'].std() if len(previous_meet) > 1 else 0\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88851397",
   "metadata": {},
   "source": [
    "## Create features for one lifter and all lifters (run above first to confirm features to engineer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12930e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lifters: 158815\n",
      "\n",
      "Feature engineering complete!\n",
      "Training examples created: 212875\n",
      "73582 lifters with 2+ meets\n"
     ]
    }
   ],
   "source": [
    "def process_single_lifter(lifter_data):\n",
    "    lifting_data = []\n",
    "\n",
    "    for i in range(1, len(lifter_data)):\n",
    "        current = lifter_data.iloc[i]\n",
    "        previous = lifter_data.iloc[:i]\n",
    "        features = create_features(current, previous)\n",
    "        lifting_data.append(features)\n",
    "    return pd.DataFrame(lifting_data)\n",
    "\n",
    "def engineer_features(df, meets=2):\n",
    "    print(f'Total lifters: {df[\"Name\"].nunique()}')\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values(['Name', 'Date']).reset_index(drop=True) # sort by name, date\n",
    "    all_lifting_data = []\n",
    "\n",
    "    for name, lifter_data in df.groupby('Name'): # for each lifters competition history\n",
    "        if len(lifter_data) < meets: # only can predict lifters with at least two comp history\n",
    "            continue\n",
    "        features = process_single_lifter(lifter_data)\n",
    "        all_lifting_data.append(features)\n",
    "\n",
    "    result = pd.concat(all_lifting_data)\n",
    "\n",
    "    print(f\"\\nFeature engineering complete!\")\n",
    "    print(f\"Training examples created: {len(result)}\")\n",
    "    print(f\"{result['Name'].nunique()} lifters with 2+ meets\")\n",
    "    return result\n",
    "\n",
    "df = pd.read_csv('../data/2-preprocessed/openpowerlifting-IPF-clean_MIN.csv')\n",
    "\n",
    "df_with_features = engineer_features(df)\n",
    "df_with_features.to_csv('../data/3-features/IPF_features_train_test.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe694c0",
   "metadata": {},
   "source": [
    "## DATASET SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07b229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1967-02-26 00:00:00 - 2024-02-24 00:00:00\n",
      "test 2024-02-29 00:00:00 - 2025-09-21 00:00:00\n"
     ]
    }
   ],
   "source": [
    "df_with_features = pd.read_csv('../data/3-features/IPF_features_train_test.csv')\n",
    "# sort by date, to prepare for training\n",
    "df_with_features['Date'] = pd.to_datetime(df_with_features['Date'])\n",
    "df_with_features = df_with_features.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "split_dataset = df_with_features['Date'].quantile(0.8)\n",
    "\n",
    "train_df = df_with_features[df_with_features['Date'] < split_dataset].copy()\n",
    "test_df = df_with_features[df_with_features['Date'] >= split_dataset]\n",
    "\n",
    "print(f'train {train_df[\"Date\"].min()} - {train_df[\"Date\"].max()}')\n",
    "print(f'test {test_df[\"Date\"].min()} - {test_df[\"Date\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84297d45",
   "metadata": {},
   "source": [
    "## SELECT FEATURES, ENCODING, IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0b29936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81.35]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TotalKg",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4dd22224-e212-4cc9-afb6-d13057de370d",
       "rows": [
        [
         "TotalKg",
         "1.0"
        ],
        [
         "Best3SquatKg",
         "0.9792701052629037"
        ],
        [
         "Best3DeadliftKg",
         "0.9740529802865633"
        ],
        [
         "Best3BenchKg",
         "0.9539527715626881"
        ],
        [
         "avg_squat",
         "0.9449199022435499"
        ],
        [
         "prev_squat",
         "0.9434509222953574"
        ],
        [
         "avg_deadlift",
         "0.9409459583293911"
        ],
        [
         "prev_deadlift",
         "0.9387666044243242"
        ],
        [
         "prev_bench",
         "0.9289953395732914"
        ],
        [
         "avg_bench",
         "0.922489515449126"
        ],
        [
         "BodyweightKg",
         "0.6902575096400582"
        ],
        [
         "total_bodyweight_ratio",
         "0.6358751587574778"
        ],
        [
         "total_std",
         "0.26687194671016945"
        ],
        [
         "total_meets",
         "0.15689169882464865"
        ],
        [
         "bodyweight_change",
         "0.06905068295138407"
        ],
        [
         "days_since_last_meet",
         "0.043095887656210356"
        ],
        [
         "percent_gain_since_last",
         "-0.01694049148346364"
        ],
        [
         "avg_improvement_rate",
         "-0.018366753882450126"
        ],
        [
         "Age",
         "-0.05961784583694305"
        ],
        [
         "Sex",
         null
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 20
       }
      },
      "text/plain": [
       "TotalKg                    1.000000\n",
       "Best3SquatKg               0.979270\n",
       "Best3DeadliftKg            0.974053\n",
       "Best3BenchKg               0.953953\n",
       "avg_squat                  0.944920\n",
       "prev_squat                 0.943451\n",
       "avg_deadlift               0.940946\n",
       "prev_deadlift              0.938767\n",
       "prev_bench                 0.928995\n",
       "avg_bench                  0.922490\n",
       "BodyweightKg               0.690258\n",
       "total_bodyweight_ratio     0.635875\n",
       "total_std                  0.266872\n",
       "total_meets                0.156892\n",
       "bodyweight_change          0.069051\n",
       "days_since_last_meet       0.043096\n",
       "percent_gain_since_last   -0.016940\n",
       "avg_improvement_rate      -0.018367\n",
       "Age                       -0.059618\n",
       "Sex                             NaN\n",
       "Name: TotalKg, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "feature_columns = [\n",
    "    'prev_squat', 'prev_bench', 'prev_deadlift', \n",
    "    'avg_squat', 'avg_bench', 'avg_deadlift',\n",
    "    'days_since_last_meet', 'total_meets',\n",
    "    'total_bodyweight_ratio',\n",
    "    'percent_gain_since_last', 'bodyweight_change', #'avg_improvement_rate', 'total_std',\n",
    "    # 'Sex_M', 'Sex_F',\n",
    "]\n",
    "\n",
    "# label/ordinal encoding can lead to model learning that there's a relationship between these categories, \n",
    "# as these sex/gender has no relationship, avoid using to prevent this\n",
    "# but this works on xgboosts with 'enable_categorical'\n",
    "train_df['Sex'] = train_df['Sex'].map({'M': 1, 'F': 0})\n",
    "feature_columns.append('Sex')\n",
    "train_df['Sex'].astype('category')\n",
    "\n",
    "# imputation methods\n",
    "# print(train_df[train_df['BodyweightKg'].isnull()])\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train_df['BodyweightKg'] = imputer.fit_transform(train_df[['BodyweightKg']])\n",
    "print(imputer.statistics_)\n",
    "\n",
    "'''BUCKETIZE AGE WITH DIVISION GROUPS??'''\n",
    "# drop age, too many missing values for imputation, not using for training\n",
    "# train_df = train_df.drop(columns=['Age'])\n",
    "\n",
    "# fill na with 0? over 30k rows of missing age\n",
    "# print(train_df.isnull().sum())\n",
    "# train_df[feature_columns] = train_df[feature_columns].fillna(0)\n",
    "\n",
    "correlation = train_df.corr(numeric_only=True)\n",
    "correlation['TotalKg'].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc667e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0, MAE=23.41, RMSE=38.27, MSE=1464.59, R2=0.940\n",
      "Fold 1, MAE=22.93, RMSE=38.14, MSE=1454.66, R2=0.940\n",
      "Fold 2, MAE=23.44, RMSE=38.65, MSE=1493.44, R2=0.937\n",
      "Fold 3, MAE=24.89, RMSE=40.03, MSE=1602.56, R2=0.932\n",
      "Fold 4, MAE=22.04, RMSE=37.30, MSE=1391.21, R2=0.940\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# TIME SERIES CROSS VALIDATIONS\n",
    "X = train_df[feature_columns]\n",
    "y = train_df['TotalKg']\n",
    "scores = {'mae': [], 'rmse': [], 'mse': [], 'r2': []}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for index, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    X_train, X_validate = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_validate = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # gbr = XGBRegressor(\n",
    "    #     enable_categorical=True, \n",
    "    #     max_depth=5, \n",
    "    #     learning_rate=0.3, \n",
    "    #     n_estimators=200, \n",
    "    #     subsample=0.8, \n",
    "    #     colsample_bytree=0.8,\n",
    "    #     gamma = 0,\n",
    "    #     random_state = 42\n",
    "    #     )\n",
    "    gbr = XGBRegressor(\n",
    "        enable_categorical=True, \n",
    "        max_depth=8, \n",
    "        learning_rate=0.1, \n",
    "        n_estimators=1500, \n",
    "        subsample=1, \n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=100,\n",
    "        reg_alpha=0.15,\n",
    "        gamma=1,\n",
    "        random_state = 42\n",
    "        )\n",
    "    gbr.fit(X_train, y_train)\n",
    "    gbr_y_pred = gbr.predict(X_validate)\n",
    "    # importance = gbr.feature_importances_\n",
    "\n",
    "    mae = mean_absolute_error(y_validate, gbr_y_pred)\n",
    "    rmse = root_mean_squared_error(y_validate, gbr_y_pred)\n",
    "    mse = mean_squared_error(y_validate, gbr_y_pred)\n",
    "    r2 = r2_score(y_validate, gbr_y_pred)\n",
    "    scores['mae'].append(mae)\n",
    "    scores['rmse'].append(rmse)\n",
    "    scores['mse'].append(mse)\n",
    "    scores['r2'].append(r2)\n",
    "    print(f'Fold {index}, MAE={mae:.2f}, RMSE={rmse:.2f}, MSE={mse:.2f}, R2={r2:.3f}')\n",
    "\n",
    "# sorted_importance = np.argsort(importance)[::-1]\n",
    "# x = range(len(importance))\n",
    "# labels = np.array(feature_columns)[sorted_importance]\n",
    "# plt.bar(x, importance[sorted_importance], tick_label=labels)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaad0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(XGBRegressor().get_params)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.5, 0.7, 1],\n",
    "    'learning_rate': [0.1, 0.2, 0.3], \n",
    "    'n_estimators': np.arange(200, 2000, 200), \n",
    "    'colsample_bytree': [0.9],\n",
    "    'reg_lambda': [100],\n",
    "    'reg_alpha': [0.15],\n",
    "    'gamma': [1],\n",
    "}\n",
    "\n",
    "xgb_model = XGBRegressor()\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best set of HP: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1bcd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(200, 2000, 100),\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 10],\n",
    "    'learning_rate': np.logspace(-3, 0, 20),     # 0.001 → 1.0\n",
    "    'subsample': np.linspace(0.5, 1.0, 6),\n",
    "    'colsample_bytree': np.linspace(0.5, 1.0, 6),\n",
    "    'gamma': np.linspace(0, 5, 6),\n",
    "    'reg_lambda': np.logspace(-3, 2, 10),\n",
    "    'reg_alpha': np.logspace(-3, 2, 10)\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,                  # tries 100 combos → far better than any grid!\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(random_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl-stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
